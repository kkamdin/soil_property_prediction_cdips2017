{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing PCA Dimensionality Reduction to Random Projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though Principal Components Analysis is a common choice for dimensionality reduction in machine learning, there isn't any reason to believe it's the optimal choice -- even in terms of computational efficiency.\n",
    "\n",
    "This notebook demonstrates that, when using linear model on this dataset, there isn't a compelling reason to choose projection onto the principal component vectors over projection onto randomly chosen vectors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn as skl\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=2)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn import random_projection\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the\n",
    "[Dimensionality Reduction Notebook](./Dimensionality\\ Reduction.ipynb),\n",
    "we were motivated to reduce the length of our data vectors because we had more data dimensions than we had observations, leading to\n",
    "[overfitting](./Cross\\ Validation\\ Example.ipynb)\n",
    "in our linear models.\n",
    "\n",
    "Our goal when reducing dimensions is to\n",
    "preserve information.\n",
    "For example, we might want to be able to\n",
    "recreate the original data vector from its reduced form\n",
    "with as little error as possible --\n",
    "we want to preserve information about the original data vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common first choice for reducing dimensions is PCA,\n",
    "or \"Principal Components Analysis\",\n",
    "as described in detail in the\n",
    "[Dimensionality Reduction Notebook](./Dimensionality\\ Reduction.ipynb).\n",
    "\n",
    "PCA is usually the first choice because it's\n",
    "quick and the outcomes are interpretable.\n",
    "It's also the best choice in certain cases.\n",
    "However, these cases aren't common in machine learning.\n",
    "PCA is the optimal choice, in the sense of preserving the most\n",
    "information about the original vectors in the reduced vectors,\n",
    "only if the data is distributed as a multivariate Gaussian.\n",
    "\n",
    "But there's another issue with the use of PCA as a pre-processing step:\n",
    "our overall goal isn't dimension reduction *per se*,\n",
    "it's making our machine learning algorithm perform better!\n",
    "That is, instead of preserving information about the original data vector\n",
    "in our reduced vector, we want to preserve\n",
    "the information in the original data vector\n",
    "that is useful for predicting the targets!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods that directly attempt to solve the above problem\n",
    "are called\n",
    "[information bottleneck methods](https://en.wikipedia.org/wiki/Information_bottleneck_method).\n",
    "Unfortunately, they require too much data to be\n",
    "usable in practical machine learning models\n",
    "(though [it has been claimed](https://arxiv.org/pdf/1503.02406.pdf)\n",
    "that deep neural networks solve the information bottleneck problem).\n",
    "\n",
    "Instead of finding the best choice of dimension reduction\n",
    "by directly optimizing it,\n",
    "we can instead use cross-validation to compare the performance of\n",
    "the same model with different dimension reduction methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate that this cross-validation can sometimes find unintuitive results,\n",
    "this notebook compares PCA to what you might think would be an overly-simple model:\n",
    "[random projection](https://en.wikipedia.org/wiki/Random_projection).\n",
    "In random projection,\n",
    "instead of carefully selecting the vectors onto which we project our data,\n",
    "we select them at random according to some distribution.\n",
    "The most common choice is a Gaussian distribution.\n",
    "\n",
    "Below, we run\n",
    "[cross-validation](./Cross\\ Validation\\ Example.ipynb)\n",
    "to determine the performance of randomly-chosen projections of\n",
    "size ranging from one dimension to as many dimensions as we have data points.\n",
    "\n",
    "Perhaps surprisingly, there doesn't seem to be any difference in performance on the test set between\n",
    "random projections and projections onto the principal components!\n",
    "Furthermore, we need our components to retain roughly 99% of the variance\n",
    "before we get optimal test-set performance.\n",
    "This would seem to indicate that the directions of large variance in our input data\n",
    "are not the directions of variability that are useful for predicting our targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below defines our cross-validation procedure\n",
    "and the plots we'll use to display its results.\n",
    "The code is included here, rather than squirreled away in a module,\n",
    "for transparency's sake.\n",
    "You can skip this cell and jump to the next block of text without missing anything crucial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_CV(num_splits,transforms,X,y,model):\n",
    "    \n",
    "    train_scores = np.zeros((num_splits,len(transforms)))\n",
    "    test_scores = np.zeros((num_splits,len(transforms)))\n",
    "\n",
    "    for transform_idx, transform in enumerate(transforms):\n",
    "\n",
    "        for split_idx in range(num_splits):\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                        test_size=0.2,)\n",
    "            transform.fit(X_train)\n",
    "            transformed_X_train = transform.transform(X_train)\n",
    "            transformed_X_test =  transform.transform(X_test)\n",
    "\n",
    "            model.fit(transformed_X_train,y_train)\n",
    "\n",
    "            train_score = model.score(transformed_X_train,y_train)\n",
    "            test_score = model.score(transformed_X_test,y_test)\n",
    "\n",
    "            train_scores[split_idx,transform_idx] = train_score\n",
    "            test_scores[split_idx,transform_idx] = test_score\n",
    "            \n",
    "    return train_scores, test_scores\n",
    "\n",
    "def transforms_from_schedule(to_keep_schedule,X,transform_type=\"\"):\n",
    "    \n",
    "    transforms = []\n",
    "    \n",
    "    if transform_type == \"PCA\":\n",
    "        transform = PCA\n",
    "    elif transform_type == \"random\":\n",
    "        transform = random_projection.GaussianRandomProjection\n",
    "    else:\n",
    "        raise ValueError(\"unknown transform \"+transform_type)\n",
    "    \n",
    "    for to_keep in to_keep_schedule:\n",
    "        transforms.append(transform(n_components=to_keep))\n",
    "    \n",
    "    return transforms\n",
    "\n",
    "def plot_CV(schedule,train_scores,test_scores,transform_type):\n",
    "    mean_train_scores = np.mean(train_scores,axis=0)\n",
    "    mean_test_scores = np.mean(test_scores,axis=0)\n",
    "\n",
    "    sd_train_scores = np.std(train_scores,axis=0,ddof=1)\n",
    "    sd_test_scores = np.std(test_scores,axis=0,ddof=1)\n",
    "\n",
    "    plt.errorbar(schedule,mean_train_scores,\n",
    "                     yerr=sd_train_scores,\n",
    "                 linewidth=4,alpha=0.75,\n",
    "                 label=transform_type+'-Train',\n",
    "                )\n",
    "\n",
    "    plt.errorbar(schedule,mean_test_scores,\n",
    "                     yerr=sd_test_scores,\n",
    "                 linewidth=4,alpha=0.75,\n",
    "                 label=transform_type+'-Test',\n",
    "                linestyle='--')\n",
    "\n",
    "def make_plot(schedule,train_scores,test_scores,transform_type=\"PCA\"):\n",
    "    \n",
    "    plt.figure(figsize=(12,4))\n",
    "    ax = plt.subplot(111)\n",
    "    ax.set_xscale(\"log\", nonposx='clip')\n",
    "    \n",
    "    plot_CV(schedule,train_scores,test_scores,transform_type)\n",
    "    \n",
    "    plt.ylim([0,1]);\n",
    "\n",
    "    plt.xlabel(\"Retained Dimensions\");\n",
    "    plt.ylabel(\"$R^2$\")\n",
    "    plt.legend(); plt.title(\"Train vs. Test Scores for \" +transform_type+ \" DR\");\n",
    "    \n",
    "def get_best(test_scores,to_keep_schedule):\n",
    "    \n",
    "    mean_test_scores = np.mean(test_scores,axis=0)\n",
    "    \n",
    "    best_score_index = np.argmax(mean_test_scores)\n",
    "    best_score = mean_test_scores[best_score_index]\n",
    "    best_score_num_dimensions = to_keep_schedule[best_score_index]\n",
    "    print(\"the best number of dimensions to keep is: \"+ str(best_score_num_dimensions) +\n",
    "          \"\\n with a score of: \" + str(best_score) )\n",
    "\n",
    "def produce_CV_plot(to_keep_schedule,num_splits,\n",
    "                  X,y,\n",
    "                  model=skl.linear_model.LinearRegression(),\n",
    "                 transform_type=\"PCA\"):\n",
    "    \n",
    "    transforms = transforms_from_schedule(to_keep_schedule,X,transform_type=transform_type)\n",
    "    \n",
    "    train_scores, test_scores = runCV(num_splits,transforms,X,y,model)\n",
    "    \n",
    "    make_plot(to_keep_schedule,train_scores,test_scores,transform_type=transform_type)\n",
    "    get_best(test_scores,to_keep_schedule)\n",
    "    \n",
    "    return train_scores,test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/training.csv')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_columns = [column for column in train.columns if column.startswith('m')]\n",
    "wavenumbers = [float(column.lstrip('m')) for column in data_columns]\n",
    "\n",
    "output_columns = [\"Ca\",\"P\",\"pH\",\"SOC\",\"Sand\"]\n",
    "\n",
    "X = train[data_columns].as_matrix()\n",
    "y = train[output_columns].as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Cross-Validation and Comparing Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading the data, we set our cross-validation schedule:\n",
    "the values of the hyperparameter that we will check via cross-validation.\n",
    "A hyperparameter is any setting of our model that determines\n",
    "what result we get but which we don't directly fit via the data.\n",
    "In our case, the hyperparameter is the number of retained dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_keep_schedule = [1,2,3,4,5,6,7,8,9,\n",
    "                    10,20,30,50,\n",
    "                    100,200,\n",
    "                    1157,\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When performing cross-validation,\n",
    "we artificially generate test sets by leaving some of our\n",
    "training data out.\n",
    "We then determine how well our algorithm performs on the held out data.\n",
    "\n",
    "This is intended to simulate how well the algorithm would perform if we \n",
    "were to collect some data,\n",
    "train on it,\n",
    "and then collect new data.\n",
    "\n",
    "The process of picking some data to keep in the training set\n",
    "and some to put in the mock test set is called\n",
    "*splitting*.\n",
    "It's implemented by\n",
    "`sklearn.model_selection.train_test_split`.\n",
    "\n",
    "Just like the performance of our algorithm\n",
    "on new data is a random variable\n",
    "(after all, the new data is random!),\n",
    "the performance on randomly-chosen held-out data\n",
    "is also random.\n",
    "\n",
    "Just like with data variables,\n",
    "we're interested in the distribution of this random value:\n",
    "what is it's center, and how is it spread?\n",
    "And again just like with data variables,\n",
    "we determine this by drawing multiple samples.\n",
    "In this case, that means selecting multiple random splits\n",
    "of the data into training and testing sets.\n",
    "\n",
    "This value is determined by `num_splits` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_splits = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now run our cross-validation procedure\n",
    "for each of the hyperparameter settings.\n",
    "We then plot the performance\n",
    "(in this case, $R^2$, or \"fraction of variance explained\")\n",
    "on the train and test sets\n",
    "as a function of the hyperparameter.\n",
    "\n",
    "Both values are plotted as mean Â± standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "PCA_train_scores, PCA_test_scores = produce_CV_plot(to_keep_schedule,num_splits,\n",
    "             X,y,\n",
    "             );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now repeat the above procedure for randomly-chosen projections.\n",
    "\n",
    "Because the randomness of our choice of projection adds more randomness\n",
    "to our estimate of the performance on the test set,\n",
    "we increase the number of splits so that the quality of our estimate stays the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_keep_schedule = [1,2,3,4,5,6,7,8,9,\n",
    "                    10,20,30,50,\n",
    "                    100,200,\n",
    "                    1157,\n",
    "                   ]\n",
    "num_splits = 20\n",
    "\n",
    "random_train_scores, random_test_scores = produce_CV_plot(to_keep_schedule,num_splits,\n",
    "             X,y,transform_type=\"random\"\n",
    "             );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strikingly, the overall shape of the plots is roughly the same, as is the performance of the best model.\n",
    "\n",
    "The cell below puts both of the plots above onto the same axes.\n",
    "Here we can see that PCA somewhat consistently outperforms random projection\n",
    "for choices of between 5 and 10 dimensions retained,\n",
    "but random projection catches up after that,\n",
    "with both methods showing roughly equal performance\n",
    "in the region where performance is best,\n",
    "between 50 and 200 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparison_plot(to_keep_schedule, PCA_train_scores, PCA_test_scores,\n",
    "                                    random_train_scores, random_test_scores,\n",
    "                                    keep_up_to=-1):\n",
    "\n",
    "    keep_up_to = -1\n",
    "    sub_schedule = to_keep_schedule[:keep_up_to];\n",
    "    plt.figure(figsize=(12,4))\n",
    "    ax = plt.subplot(111)\n",
    "\n",
    "    plot_CV(sub_schedule,\n",
    "       PCA_train_scores[:,:keep_up_to],PCA_test_scores[:,:keep_up_to],\n",
    "       transform_type=\"PCA\")\n",
    "\n",
    "    plot_CV(sub_schedule,\n",
    "       random_train_scores[:,:keep_up_to],random_test_scores[:,:keep_up_to],\n",
    "       transform_type=\"random\")\n",
    "\n",
    "    plt.ylabel(r\"$R^2$\"); plt.xlabel(\"Retained Dimensions\")\n",
    "    plt.gca().set_xscale('log'); plt.ylim([0,1]); plt.legend();\n",
    "    plt.title(\"Train and Test Scores for PCA and Random DR\");\n",
    "    \n",
    "comparison_plot(to_keep_schedule, PCA_train_scores, PCA_test_scores,\n",
    "                                    random_train_scores, random_test_scores,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the fact that PCA\n",
    "[does an excellent job reducing the dimensionality of this dataset](./Dimensionality Reduction.iypnb)\n",
    "in terms of retaining variance,\n",
    "it doesn't seem to do a much better job of preparing the data\n",
    "for use in a linear model\n",
    "than random projection.\n",
    "\n",
    "Indeed, both models perform their best when the number of retained dimensions in around 100,\n",
    "at which point there is a\n",
    "[mathematical expectation](http://scikit-learn.org/stable/auto_examples/plot_johnson_lindenstrauss_bound.html)\n",
    "that the random projection will preserve lots of information about the input.\n",
    "\n",
    "This would seem to indicate that the biggest variations in our input data\n",
    "doesn't do a great job predicting variation in our output data.\n",
    "Instead, very particular small changes to the input data are important,\n",
    "and the only way to guarantee they are preserved in the reduced data vectors\n",
    "is to preserve almost all of the variation in the input data\n",
    "by retaining a fairly large number of dimensions.\n",
    "\n",
    "The findings in this notebook demonstrate that,\n",
    "just like more traditional hyperparameters,\n",
    "dimensionality reduction choices,\n",
    "and other pre-processing choices,\n",
    "should be cross-validated,\n",
    "in the absence of any guarantees\n",
    "that they are optimal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
